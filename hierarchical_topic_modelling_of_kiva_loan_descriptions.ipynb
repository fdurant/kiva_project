{
 "metadata": {
  "name": "",
  "signature": "sha256:8ef930f0ec56f3fd9cf8d1052afe028cc2dd4e1c2e65c746cf1a1407bd65fd74"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hierarchical topic modelling of Kiva loan descriptions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Goals"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*  Create a visual explorer for a static set of 800K+ English loan descriptions from Kiva.org\n",
      "*  Use (hierarchical) topic modelling\n",
      "*  Publish the explorer to the world"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* David Mimno and Andrew MacCallum: [Organizing the OCA: Learning Faceted Subjects from a Library of Digital Books](http://mimno.infosci.cornell.edu/papers/f129-mimno.pdf) => bottom-up approach\n",
      "* Jay Pujara and Peter Skomoroch: [Large-Scale Hierarchical Topic Models](http://linqs.cs.umd.edu/basilic/web/Publications/2012/pujara:nips12/pujara_biglearn12.pdf) => top-down approach\n",
      "* Alison Smith, Timothy Hawes, and Meredith Myers: [Hi&eacute;rarchie: Interactive Visualization for Hierarchical Topic Models](http://nlp.stanford.edu/events/illvi2014/papers/smith-illvi2014b.pdf)\n",
      "* Hierarchie [Readme page at GitHub](http://mlvl.github.io/Hierarchie/#/about)\n",
      "* [Gensim - topic modelling for humans](https://radimrehurek.com/gensim/index.html)\n",
      "* Nikolaos Aletras and Mark Stevenson: [Measuring the Similarity between Automatically Generated Topics](http://staffwww.dcs.shef.ac.uk/people/N.Aletras/resources/2014_eacl_topicSim_short.pdf)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Approach"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Use gensim to derive flat topic models over (part of) the Kiva corpus, taking the [tutorial](https://radimrehurek.com/gensim/tutorial.html) as guideline\n",
      "* Organize the found topic models into a hierarchy - no precise idea yet on how to do this (maybe some form of hierarchical clustering may apply)\n",
      "* Convert that hierarchy into a [JSON data file](https://github.com/mlvl/Hierarchie/tree/gh-pages/app/data) compliant with Hierarchie\n",
      "* Visualize everything with Hierarchie\n",
      "\n",
      "IMPORTANT: store python code in scripts, and call these from ipython notebook"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 1: download [Kiva data dump (JSON format)](http://s3.kiva.org/snapshots/kiva_ds_json.zip), and extract into data/static"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 2: since the 'description' fields in the Kiva data dump often mix multiple languages (due to manual translations), the language codes are not reliable. Therefore, we:\n",
      "\n",
      "* split the descriptions in paragraps\n",
      "* do language detection on the paragraphs\n",
      "* store the recombined paragraphs and their language code in new processed_description field\n",
      "\n",
      "The data are written to a locally installed MongoDB 'kiva', collection 'loans'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next line commented out because we only want to run this once\n",
      "# nohup python src/load_kiva_to_mongodb.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 3: load (a subset) of the English data from MongoDB, and convert it to the [Blei LDA-C format](http://www.cs.princeton.edu/~blei/lda-c/), using a [gensim utility function](https://radimrehurek.com/gensim/tut1.html#corpus-formats)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python src/convert_mongodb_to_blei_ldac.py --dataDir data/topicmodelling\\\n",
      "                                            --corpusBaseName kiva \\\n",
      "                                            --stopwordFile=data/topicmodelling/kiva_stopwords.tsv \\\n",
      "                                            --maxNrDocs 20000 \\\n",
      "                                            --filterBelow 10 \\\n",
      "                                            --filterAbove 99.0 \\\n",
      "                                            --filterKeepN 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating MongoDB cursor ... done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of loans in 'en' since 2010: 624364\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First pass: streaming from MongoDB ...\r\n",
        "creating the dictionary ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 5000 documents ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 10000 documents ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 15000 documents ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "filtering the dictionary ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\r\n",
        "wrote data/topicmodelling/kiva_dict.bin ... and data/topicmodelling/kiva_dict.txt ... done\r\n",
        "Second pass: streaming from MongoDB ... saving into data/topicmodelling/kiva.lda-c (Blei corpus format) ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\r\n",
        "Number of documents converted: 20000\r\n",
        "Vocabulary size: 1000\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python src/model_topics.py --dataDir data/topicmodelling \\\n",
      "                            --modelDir data/topicmodelling \\\n",
      "                            --corpusBaseName kiva \\\n",
      "                            --nrTopics 64 \\\n",
      "                            --nrWords 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading Blei corpus file data/topicmodelling/kiva.lda-c ... done\r\n",
        "<gensim.corpora.bleicorpus.BleiCorpus object at 0x106867ad0>\r\n",
        "Dictionary(1000 unique tokens: [u'neighbors', u'shop', u'managed', u'alleviation', u'lack']...)\r\n",
        "Making topic model ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\r\n",
        "0.038*home + 0.036*loans + 0.034*volunteer + 0.031*spanish + 0.028*reodica + 0.028*ronan + 0.024*children + 0.023*better + 0.022*years + 0.020*used\r\n",
        "0.035*years + 0.027*old + 0.023*learn + 0.023*business + 0.021*children + 0.019*also + 0.017*grade + 0.017*war + 0.016*finance + 0.015*care\r\n",
        "0.023*members + 0.021*work + 0.014*years + 0.013*volunteer + 0.013*mfp + 0.013*spanish + 0.012*selling + 0.011*children + 0.011*buy + 0.011*group\r\n",
        "0.030*community + 0.030*weekly + 0.027*business + 0.023*family + 0.020*loans + 0.019*capital + 0.019*groups + 0.019*sure + 0.017*used + 0.016*partners\r\n",
        "0.053*per + 0.044*day + 0.040*earning + 0.036*income + 0.033*business + 0.033*usd + 0.032*family + 0.028*since + 0.028*husband + 0.027*children\r\n",
        "0.080*business + 0.030*products + 0.027*years + 0.024*small + 0.022*started + 0.021*store + 0.021*income + 0.018*merchandise + 0.017*improved + 0.017*would\r\n",
        "0.027*credit + 0.025*possible + 0.023*improve + 0.023*hopes + 0.022*minutes + 0.022*children + 0.021*within + 0.018*economically + 0.018*living + 0.017*get\r\n",
        "0.058*d. + 0.047*family + 0.045*conditions + 0.040*living + 0.039*improve + 0.039*v. + 0.032*jane + 0.021*thus + 0.018*support + 0.018*income\r\n",
        "0.047*t. + 0.046*husband + 0.033*children + 0.027*resides + 0.024*however + 0.022*day + 0.019*married + 0.018*business + 0.018*age + 0.018*fish\r\n",
        "0.060*2nd + 0.052*starting + 0.034*bananas + 0.028*50 + 0.028*business + 0.021*additional + 0.018*15,000 + 0.017*35 + 0.016*44 + 0.016*2009\r\n",
        "0.060*business + 0.054*shop + 0.047*oil + 0.035*cooking + 0.033*years + 0.032*sugar + 0.031*retail + 0.030*rice + 0.023*items + 0.021*goods\r\n",
        "0.106*benin + 0.052*fishing + 0.052*business + 0.032*requesting + 0.022*lives + 0.021*client + 0.019*amount + 0.019*international + 0.018*another + 0.018*living\r\n",
        "0.029*business + 0.028*women + 0.025*family + 0.024*life + 0.021*hard + 0.020*php + 0.018*living + 0.018*member + 0.017*lives + 0.017*help\r\n",
        "0.043*bank + 0.033*communal + 0.032*member + 0.030*spanish + 0.028*volunteer + 0.025*sells + 0.023*children + 0.021*translated + 0.020*years + 0.020*buy\r\n",
        "0.103*international + 0.068*thousands + 0.034*seek + 0.032*clients + 0.027*even + 0.025*communities + 0.022*conditions + 0.022*southern + 0.020*provide + 0.017*obtain\r\n",
        "0.146*k. + 0.059*o. + 0.044*managing + 0.029*apply + 0.018*business + 0.017*staff + 0.017*basis + 0.016*money + 0.014*profit + 0.014*month\r\n",
        "0.071*daughters + 0.055*buys + 0.054*resale + 0.039*married + 0.036*since + 0.036*two + 0.035*kilometers + 0.034*phnom + 0.033*penh + 0.025*city\r\n",
        "0.062*work + 0.035*business + 0.023*working + 0.022*since + 0.018*mainly + 0.018*time + 0.017*requested + 0.017*plans + 0.017*always + 0.015*first\r\n",
        "0.046*lending + 0.033*? + 0.030*http + 0.030*team + 0.028*please + 0.024*enterprise + 0.024*across + 0.023*founded + 0.023*join + 0.023*country\r\n",
        "0.029*years + 0.028*children + 0.023*women + 0.019*family + 0.016*volunteer + 0.015*married + 0.015*sells + 0.015*average + 0.014*clothing + 0.013*group\r\n",
        "0.241*e. + 0.187*managed + 0.064*generating + 0.038*business + 0.035*helping + 0.013*years + 0.011*living + 0.010*income + 0.010*f. + 0.010*selling\r\n",
        "0.040*business + 0.039*hspfi + 0.021*php + 0.017*template + 0.017*translation + 0.015*years + 0.015*living + 0.014*activities + 0.014*additional + 0.012*city\r\n",
        "0.061*group + 0.039*business + 0.034*years + 0.023*children + 0.022*leader + 0.022*photo + 0.019*school + 0.019*buy + 0.016*wants + 0.015*one\r\n",
        "0.035*pmpc + 0.034*business + 0.023*php + 0.018*living + 0.018*template + 0.018*translation + 0.017*using + 0.016*additional + 0.015*years + 0.014*improve\r\n",
        "0.052*children + 0.048*fish + 0.043*business + 0.042*years + 0.035*sells + 0.026*school + 0.025*husband + 0.024*married + 0.020*old + 0.020*bags\r\n",
        "0.051*store + 0.038*business + 0.025*support + 0.024*children + 0.022*family + 0.021*poor + 0.017*husband + 0.016*additional + 0.016*philippines + 0.015*credit\r\n",
        "0.048*school + 0.038*children + 0.032*years + 0.031*family + 0.027*born + 0.022*loans + 0.020*business + 0.019*married + 0.018*mother + 0.017*expenses\r\n",
        "0.046*business + 0.040*maria + 0.036*group + 0.032*clothing + 0.028*use + 0.024*home + 0.023*clothes + 0.023*invest + 0.021*children + 0.018*profits\r\n",
        "0.024*customers + 0.024*buy + 0.022*mar\u00eda + 0.020*spanish + 0.019*business + 0.019*children + 0.019*drinks + 0.019*volunteer + 0.015*soft + 0.012*years\r\n",
        "0.107*group + 0.030*member + 0.028*business + 0.028*offered + 0.028*responsible + 0.028*receives + 0.027*back + 0.027*individual + 0.026*fellow + 0.025*leader\r\n",
        "0.043*business + 0.043*charcoal + 0.043*kadet + 0.042*years + 0.030*town + 0.027*plans + 0.026*use + 0.025*children + 0.024*married + 0.021*buy\r\n",
        "0.039*brac + 0.026*organizations + 0.023*village + 0.022*children + 0.017*programs + 0.016*returning + 0.016*approach + 0.015*14,000 + 0.015*range + 0.015*largest\r\n",
        "0.048*mrs. + 0.034*husband + 0.031*mr. + 0.026*family + 0.023*children + 0.023*one + 0.022*support + 0.021*rice + 0.020*village + 0.018*school\r\n",
        "0.154*m. + 0.056*c. + 0.053*teacher + 0.043*lady + 0.034*mrs. + 0.026*students + 0.026*people + 0.025*school + 0.022*business + 0.022*children\r\n",
        "0.028*years + 0.027*construction + 0.025*children + 0.025*house + 0.023*materials + 0.022*finish + 0.020*worked + 0.019*country + 0.018*production + 0.018*raised\r\n",
        "0.036*sons + 0.035*two + 0.034*hair + 0.030*salon + 0.025*children + 0.025*business + 0.024*car + 0.023*son + 0.021*beauty + 0.021*years\r\n",
        "0.121*involved + 0.098*8 + 0.044*plan + 0.031*4 + 0.025*years + 0.023*children + 0.023*2 + 0.022*married + 0.020*large + 0.020*54\r\n",
        "0.045*house + 0.029*lives + 0.026*volunteer + 0.026*spanish + 0.023*works + 0.021*translated + 0.019*home + 0.018*city + 0.017*work + 0.014*buy\r\n",
        "0.060*gdmpc + 0.029*business + 0.028*del + 0.019*2010 + 0.018*php + 0.018*living + 0.017*sur + 0.017*misamis + 0.016*occidental + 0.014*translation\r\n",
        "0.063*still + 0.060*today + 0.043*man + 0.030*business + 0.027*years + 0.026*working + 0.022*nearly + 0.021*soon + 0.021*requesting + 0.020*married\r\n",
        "0.380*cosmetics + 0.178*37 + 0.104*transport + 0.045*public + 0.023*business + 0.014*children + 0.013*sells + 0.011*years + 0.009*c. + 0.007*married\r\n",
        "0.074*farm + 0.029*rice + 0.027*children + 0.025*years + 0.023*buy + 0.022*needs + 0.021*farming + 0.021*family + 0.021*old + 0.017*supplies\r\n",
        "0.067*n. + 0.048*income + 0.040*business + 0.027*buy + 0.023*family + 0.023*increase + 0.022*husband + 0.022*wants + 0.020*years + 0.018*children\r\n",
        "0.068*j. + 0.063*current + 0.062*san + 0.046*child + 0.032*personal + 0.022*products + 0.019*business + 0.017*district + 0.016*bought + 0.016*one\r\n",
        "0.112*group + 0.057*members + 0.032*b. + 0.029*businesses + 0.029*women + 0.026*\u2013 + 0.023*share + 0.019*f. + 0.015*city + 0.014*sales\r\n",
        "0.114*55 + 0.111*cycle + 0.061*11 + 0.060*primarily + 0.053*goals + 0.037*adult + 0.034*seven + 0.025*business + 0.019*years + 0.016*amount\r\n",
        "0.072*3 + 0.041*level + 0.031*business + 0.029*education + 0.024*social + 0.023*higher + 0.023*`` + 0.022*provided + 0.019*household + 0.019*lending\r\n",
        "0.039*business + 0.035*years + 0.031*woman + 0.026*restaurant + 0.024*old + 0.024*promises + 0.021*opportunity + 0.018*district + 0.018*hardworking + 0.016*children\r\n",
        "0.054*business + 0.032*daughter + 0.025*years + 0.021*family + 0.021*wife + 0.021*husband + 0.021*usd + 0.020*lives + 0.020*working + 0.019*old\r\n",
        "0.079*business + 0.035*years + 0.025*kenya + 0.024*children + 0.023*kes + 0.020*hopes + 0.019*future + 0.018*faulu + 0.017*two + 0.015*requested\r\n",
        "0.079*s. + 0.060*vehicle + 0.054*motorcycle + 0.032*transportation + 0.031*repair + 0.030*applied + 0.028*taxi + 0.027*service + 0.023*feed + 0.022*living\r\n",
        "0.035*milk + 0.030*farming + 0.028*crops + 0.027*also + 0.026*years + 0.025*cattle + 0.023*children + 0.022*animals + 0.021*agriculture + 0.020*buy\r\n",
        "0.049*village + 0.045*mrs. + 0.030*members + 0.028*buy + 0.026*bank + 0.025*land + 0.022*support + 0.021*different + 0.020*kandal + 0.020*rice\r\n",
        "0.034*aski + 0.033*business + 0.020*php + 0.018*template + 0.018*translation + 0.017*living + 0.015*additional + 0.014*activities + 0.013*years + 0.013*improve\r\n",
        "0.100*h. + 0.050*develop + 0.046*silk + 0.039*finished + 0.029*business + 0.027*penh + 0.027*fifteen + 0.026*phnom + 0.026*years + 0.025*purpose\r\n",
        "0.156*eggs + 0.112*20,000 + 0.103*existing + 0.033*46 + 0.032*business + 0.030*repair + 0.022*daily + 0.021*entrepreneur + 0.021*goods + 0.018*transport\r\n",
        "0.056*business + 0.043*group + 0.029*requesting + 0.020*support + 0.017*living + 0.017*t. + 0.016*women + 0.016*raising + 0.016*l. + 0.015*livestock\r\n",
        "0.054*store + 0.042*grocery + 0.041*vegetables + 0.033*sells + 0.028*michael + 0.026*bujazan + 0.024*fruits + 0.021*buy + 0.021*items + 0.019*spanish\r\n",
        "0.029*business + 0.028*years + 0.023*volunteer + 0.023*spanish + 0.021*products + 0.021*old + 0.019*sales + 0.019*translated + 0.013*wants + 0.012*also\r\n",
        "0.052*business + 0.042*hopes + 0.035*years + 0.035*children + 0.034*purchase + 0.033*sells + 0.032*sell + 0.032*lenders + 0.030*old + 0.028*customers\r\n",
        "0.036*shop + 0.034*dairy + 0.029*lives + 0.026*products + 0.024*order + 0.024*business + 0.021*years + 0.020*neighbors + 0.019*a. + 0.019*sells\r\n",
        "0.049*years + 0.046*bank + 0.030*old + 0.026*volunteer + 0.024*district + 0.023*communal + 0.023*lives + 0.023*children + 0.022*soles + 0.022*member\r\n",
        "0.063*business + 0.059*financially + 0.058*children\u2019s + 0.025*parts + 0.025*successful + 0.021*finance + 0.017*one + 0.017*despite + 0.016*requesting + 0.016*company\r\n",
        "0.038*country + 0.034*history + 0.032*great + 0.031*agricultural + 0.027*already + 0.024*business + 0.021*end + 0.021*low + 0.021*clients + 0.021*sector\r\n",
        "Writing model file data/topicmodelling/kiva.lda_model ... done\r\n",
        "Creating complete topic/word matrix in memory:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 1/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 2/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 3/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 4/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 5/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 6/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 7/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 8/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 9/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 10/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 11/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 12/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 13/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 14/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 15/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 16/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 17/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 18/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 19/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 20/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 21/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 22/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 23/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 24/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 25/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 26/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 27/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 28/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 29/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 30/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 31/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 32/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 33/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 34/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 35/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 36/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 37/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 38/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 39/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 40/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 41/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 42/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 43/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 44/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 45/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 46/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 47/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 48/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 49/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 50/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 51/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 52/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 53/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 54/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 55/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 56/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 57/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 58/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 59/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 60/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 61/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 62/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 63/64 ...\r\n",
        "topic 64/64 ...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing topic/word matrix file data/topicmodelling/kiva_topic_words_matrix.h5 ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/usr/local/lib/python2.7/site-packages/pandas/io/pytables.py:2486: PerformanceWarning: \r\n",
        "your performance may suffer as PyTables will pickle object types that it cannot\r\n",
        "map directly to c-types [inferred_type->unicode,key->axis0] [items->None]\r\n",
        "\r\n",
        "  warnings.warn(ws, PerformanceWarning)\r\n",
        "/usr/local/lib/python2.7/site-packages/pandas/io/pytables.py:2486: PerformanceWarning: \r\n",
        "your performance may suffer as PyTables will pickle object types that it cannot\r\n",
        "map directly to c-types [inferred_type->unicode,key->block0_items] [items->None]\r\n",
        "\r\n",
        "  warnings.warn(ws, PerformanceWarning)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done\r\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python src/build_topic_hierarchy.py --modelDir data/topicmodelling \\\n",
      "                                     --modelBaseName kiva \\\n",
      "                                     --nrClusters 3 \\\n",
      "                                     --nrWords 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading topic/word matrix file data/topicmodelling/kiva_topic_words_matrix.h5 ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\r\n",
        "Hierarchically clustering topics ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2 2\r\n",
        " 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2]\r\n",
        "dataframe indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\r\n",
        "clusterCounts =  {0: 5, 1: 1, 2: 58}\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
        " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n",
        "dataframe indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\r\n",
        "clusterCounts =  {0: 56, 1: 1, 2: 1}\r\n",
        "clusters =  [2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2\r\n",
        " 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dataframe indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\r\n",
        "clusterCounts =  {0: 6, 1: 1, 2: 49}\r\n",
        "clusters =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
        " 0 0 0 0 1 0 0 0 0 0 0 0]\r\n",
        "dataframe indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63]\r\n",
        "clusterCounts =  {0: 47, 1: 1, 2: 1}\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 0 0 0 1 1 0 1 1 1 1 1 0 0 2 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1\r\n",
        " 1 0 1 0 0 1 0 0 1 0]\r\n",
        "dataframe indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 62, 63]\r\n",
        "clusterCounts =  {0: 25, 1: 21, 2: 1}\r\n",
        "clusters =  [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1]\r\n",
        "dataframe indices = [0, 1, 2, 3, 6, 13, 14, 17, 18, 19, 26, 28, 31, 34, 35, 36, 37, 43, 47, 51, 57, 58, 60, 61, 63]\r\n",
        "clusterCounts =  {0: 1, 1: 23, 2: 1}\r\n",
        "clusters =  [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 0 1]\r\n",
        "dataframe indices = [0, 1, 2, 3, 6, 13, 17, 18, 19, 26, 28, 31, 34, 35, 37, 43, 47, 51, 57, 58, 60, 61, 63]\r\n",
        "clusterCounts =  {0: 2, 1: 20, 2: 1}\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1]\r\n",
        "dataframe indices = [0, 1, 2, 3, 6, 17, 18, 19, 26, 28, 31, 34, 35, 37, 47, 51, 57, 58, 60, 63]\r\n",
        "clusterCounts =  {0: 18, 1: 1, 2: 1}\r\n",
        "clusters =  [1 1 1 2 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\r\n",
        "dataframe indices = [0, 1, 2, 3, 6, 17, 19, 26, 28, 31, 34, 35, 37, 47, 51, 57, 58, 60]\r\n",
        "clusterCounts =  {0: 1, 1: 16, 2: 1}\r\n",
        "clusters =  [0 2 2 2 2 2 2 2 0 2 0 2 2 1 2 2]\r\n",
        "dataframe indices = [0, 1, 2, 6, 17, 19, 26, 28, 34, 35, 37, 47, 51, 57, 58, 60]\r\n",
        "clusterCounts =  {0: 3, 1: 1, 2: 12}\r\n",
        "clusters =  [1 1 1 1 1 1 1 2 1 0 1 1]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dataframe indices = [1, 2, 6, 17, 19, 26, 28, 35, 47, 51, 58, 60]\r\n",
        "clusterCounts =  {0: 1, 1: 10, 2: 1}\r\n",
        "clusters =  [0 1 1 1 0 0 1 1 1 2]\r\n",
        "dataframe indices = [1, 2, 6, 17, 19, 26, 28, 47, 58, 60]\r\n",
        "clusterCounts =  {0: 3, 1: 6, 2: 1}\r\n",
        "clusters =  [0 1 2 0 0 0]\r\n",
        "dataframe indices = [2, 6, 17, 28, 47, 58]\r\n",
        "clusterCounts =  {0: 4, 1: 1, 2: 1}\r\n",
        "clusters =  [0 2 1 0]\r\n",
        "dataframe indices = [2, 28, 47, 58]\r\n",
        "clusterCounts =  {0: 2, 1: 1, 2: 1}\r\n",
        "hierarchyAsList[2] = 0\r\n",
        "hierarchyAsList[58] = 0\r\n",
        "hierarchyAsList[47] = 1\r\n",
        "hierarchyAsList[28] = 2\r\n",
        "\r\n",
        "hierarchyAsList[6] = 3\r\n",
        "hierarchyAsList[17] = 4\r\n",
        "\r\n",
        "hierarchyAsList[1] = 5\r\n",
        "hierarchyAsList[19] = 5\r\n",
        "hierarchyAsList[26] = 5\r\n",
        "hierarchyAsList[60] = 6\r\n",
        "\r\n",
        "hierarchyAsList[51] = 7\r\n",
        "hierarchyAsList[35] = 8\r\n",
        "\r\n",
        "hierarchyAsList[0] = 9\r\n",
        "hierarchyAsList[34] = 9\r\n",
        "hierarchyAsList[37] = 9\r\n",
        "hierarchyAsList[57] = 10\r\n",
        "\r\n",
        "hierarchyAsList[31] = 11\r\n",
        "hierarchyAsList[3] = 12\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hierarchyAsList[63] = 13\r\n",
        "hierarchyAsList[18] = 14\r\n",
        "\r\n",
        "hierarchyAsList[13] = 15\r\n",
        "hierarchyAsList[61] = 15\r\n",
        "hierarchyAsList[43] = 16\r\n",
        "\r\n",
        "hierarchyAsList[14] = 17\r\n",
        "hierarchyAsList[36] = 18\r\n",
        "\r\n",
        "clusters =  [1 1 1 2 0 1 1 0 1 0 2 1 2 2 1 1 0 2 2 0 1]\r\n",
        "dataframe indices = [4, 5, 7, 8, 10, 11, 12, 24, 25, 30, 32, 39, 41, 42, 46, 48, 49, 50, 52, 59, 62]\r\n",
        "clusterCounts =  {0: 5, 1: 10, 2: 6}\r\n",
        "clusters =  [0 0 1 2 0 0 0 0 0 0]\r\n",
        "dataframe indices = [4, 5, 7, 11, 12, 25, 39, 46, 48, 62]\r\n",
        "clusterCounts =  {0: 8, 1: 1, 2: 1}\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 1 1 1 1 2 1 1]\r\n",
        "dataframe indices = [4, 5, 12, 25, 39, 46, 48, 62]\r\n",
        "clusterCounts =  {0: 1, 1: 6, 2: 1}\r\n",
        "clusters =  [1 1 1 0 1 2]\r\n",
        "dataframe indices = [5, 12, 25, 39, 48, 62]\r\n",
        "clusterCounts =  {0: 1, 1: 4, 2: 1}\r\n",
        "clusters =  [1 2 1 0]\r\n",
        "dataframe indices = [5, 12, 25, 48]\r\n",
        "clusterCounts =  {0: 1, 1: 2, 2: 1}\r\n",
        "hierarchyAsList[5] = 19\r\n",
        "hierarchyAsList[25] = 19\r\n",
        "hierarchyAsList[48] = 20\r\n",
        "hierarchyAsList[12] = 21\r\n",
        "\r\n",
        "hierarchyAsList[39] = 22\r\n",
        "hierarchyAsList[62] = 23\r\n",
        "\r\n",
        "hierarchyAsList[4] = 24\r\n",
        "hierarchyAsList[46] = 25\r\n",
        "\r\n",
        "hierarchyAsList[7] = 26\r\n",
        "hierarchyAsList[11] = 27\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 1 0 0 2 1]\r\n",
        "dataframe indices = [8, 32, 41, 42, 50, 52]\r\n",
        "clusterCounts =  {0: 3, 1: 2, 2: 1}\r\n",
        "hierarchyAsList[8] = 28\r\n",
        "hierarchyAsList[41] = 28\r\n",
        "hierarchyAsList[42] = 28\r\n",
        "hierarchyAsList[32] = 29\r\n",
        "hierarchyAsList[52] = 29\r\n",
        "hierarchyAsList[50] = 30\r\n",
        "\r\n",
        "clusters =  [2 1 1 1 0]\r\n",
        "dataframe indices = [10, 24, 30, 49, 59]\r\n",
        "clusterCounts =  {0: 1, 1: 3, 2: 1}\r\n",
        "hierarchyAsList[24] = 31\r\n",
        "hierarchyAsList[30] = 31\r\n",
        "hierarchyAsList[49] = 31\r\n",
        "hierarchyAsList[59] = 32\r\n",
        "hierarchyAsList[10] = 33\r\n",
        "\r\n",
        "\r\n",
        "hierarchyAsList[16] = 34\r\n",
        "\r\n",
        "hierarchyAsList[54] = 35\r\n",
        "hierarchyAsList[15] = 36\r\n",
        "\r\n",
        "clusters =  [2 0 0 0 0 1]\r\n",
        "dataframe indices = [9, 21, 23, 38, 53, 55]\r\n",
        "clusterCounts =  {0: 4, 1: 1, 2: 1}\r\n",
        "clusters =  [2 0 1 0]\r\n",
        "dataframe indices = [21, 23, 38, 53]\r\n",
        "clusterCounts =  {0: 2, 1: 1, 2: 1}\r\n",
        "hierarchyAsList[23] = 37\r\n",
        "hierarchyAsList[53] = 37\r\n",
        "hierarchyAsList[38] = 38\r\n",
        "hierarchyAsList[21] = 39\r\n",
        "\r\n",
        "hierarchyAsList[55] = 40\r\n",
        "hierarchyAsList[9] = 41\r\n",
        "\r\n",
        "hierarchyAsList[33] = 42\r\n",
        "\r\n",
        "hierarchyAsList[45] = 43\r\n",
        "hierarchyAsList[20] = 44\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clusters =  [0 0 2 1 0]\r\n",
        "dataframe indices = [22, 27, 29, 44, 56]\r\n",
        "clusterCounts =  {0: 3, 1: 1, 2: 1}\r\n",
        "hierarchyAsList[22] = 45\r\n",
        "hierarchyAsList[27] = 45\r\n",
        "hierarchyAsList[56] = 45\r\n",
        "hierarchyAsList[44] = 46\r\n",
        "hierarchyAsList[29] = 47\r\n",
        "\r\n",
        "hierarchyAsList[40] = 48\r\n",
        "\r\n",
        "tree =\r\n",
        "[[[[[[[[[[[[[[[2, 58], [47], [28]], [6], [17]], [1, 19, 26], [60]],\r\n",
        "           [51],\r\n",
        "           [35]],\r\n",
        "          [0, 34, 37],\r\n",
        "          [57]],\r\n",
        "         [31],\r\n",
        "         [3]],\r\n",
        "        [63],\r\n",
        "        [18]],\r\n",
        "       [13, 61],\r\n",
        "       [43]],\r\n",
        "      [14],\r\n",
        "      [36]],\r\n",
        "     [[[[[[5, 25], [48], [12]], [39], [62]], [4], [46]], [7], [11]],\r\n",
        "      [[8, 41, 42], [32, 52], [50]],\r\n",
        "      [[24, 30, 49], [59], [10]]],\r\n",
        "     [16]],\r\n",
        "    [54],\r\n",
        "    [15]],\r\n",
        "   [[[23, 53], [38], [21]], [55], [9]],\r\n",
        "   [33]],\r\n",
        "  [45],\r\n",
        "  [20]],\r\n",
        " [[22, 27, 56], [44], [29]],\r\n",
        " [40]]\r\n",
        "recursive hierarchy:\r\n",
        "[9,\r\n",
        " 5,\r\n",
        " 0,\r\n",
        " 12,\r\n",
        " 24,\r\n",
        " 19,\r\n",
        " 3,\r\n",
        " 26,\r\n",
        " 28,\r\n",
        " 41,\r\n",
        " 33,\r\n",
        " 27,\r\n",
        " 21,\r\n",
        " 15,\r\n",
        " 17,\r\n",
        " 36,\r\n",
        " 34,\r\n",
        " 4,\r\n",
        " 14,\r\n",
        " 5,\r\n",
        " 44,\r\n",
        " 39,\r\n",
        " 45,\r\n",
        " 37,\r\n",
        " 31,\r\n",
        " 19,\r\n",
        " 5,\r\n",
        " 45,\r\n",
        " 2,\r\n",
        " 47,\r\n",
        " 31,\r\n",
        " 11,\r\n",
        " 29,\r\n",
        " 42,\r\n",
        " 9,\r\n",
        " 8,\r\n",
        " 18,\r\n",
        " 9,\r\n",
        " 38,\r\n",
        " 22,\r\n",
        " 48,\r\n",
        " 28,\r\n",
        " 28,\r\n",
        " 16,\r\n",
        " 46,\r\n",
        " 43,\r\n",
        " 25,\r\n",
        " 1,\r\n",
        " 20,\r\n",
        " 31,\r\n",
        " 30,\r\n",
        " 7,\r\n",
        " 29,\r\n",
        " 37,\r\n",
        " 35,\r\n",
        " 40,\r\n",
        " 45,\r\n",
        " 10,\r\n",
        " 0,\r\n",
        " 32,\r\n",
        " 6,\r\n",
        " 15,\r\n",
        " 23,\r\n",
        " 13]\r\n",
        "hierarchy: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
        " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\r\n",
        " done\r\n",
        "Loading model file data/topicmodelling/kiva.lda_model ... done\r\n",
        "Building nested hierarchy in memory ... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done\r\n",
        " Dumping object hierarchy into JSON file data/topicmodelling/kivadata.json ... done\r\n"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Finally:\n",
      "* calculate for each document its distribution over topics (original goal of this script!)\n",
      "* link the IDs of the documents (i.e. their Kiva IDS) as subleaves to the bottom topics, (majority vote)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}